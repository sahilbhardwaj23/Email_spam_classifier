{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('training_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>num_stop_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_punctuation_chars</th>\n",
       "      <th>word_count_after_preprocessing</th>\n",
       "      <th>num_chars_after_preprocessing</th>\n",
       "      <th>vector_dim_1</th>\n",
       "      <th>vector_dim_2</th>\n",
       "      <th>vector_dim_3</th>\n",
       "      <th>...</th>\n",
       "      <th>vector_dim_91</th>\n",
       "      <th>vector_dim_92</th>\n",
       "      <th>vector_dim_93</th>\n",
       "      <th>vector_dim_94</th>\n",
       "      <th>vector_dim_95</th>\n",
       "      <th>vector_dim_96</th>\n",
       "      <th>vector_dim_97</th>\n",
       "      <th>vector_dim_98</th>\n",
       "      <th>vector_dim_99</th>\n",
       "      <th>vector_dim_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>82</td>\n",
       "      <td>-0.445367</td>\n",
       "      <td>-0.101509</td>\n",
       "      <td>-1.050856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363760</td>\n",
       "      <td>0.423471</td>\n",
       "      <td>-0.183125</td>\n",
       "      <td>0.123134</td>\n",
       "      <td>0.421487</td>\n",
       "      <td>-0.085384</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>-0.311313</td>\n",
       "      <td>0.590059</td>\n",
       "      <td>-0.068110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.336330</td>\n",
       "      <td>-0.172123</td>\n",
       "      <td>-0.879673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178105</td>\n",
       "      <td>0.469185</td>\n",
       "      <td>-0.159354</td>\n",
       "      <td>0.181287</td>\n",
       "      <td>0.370253</td>\n",
       "      <td>-0.151212</td>\n",
       "      <td>-0.029242</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>0.309134</td>\n",
       "      <td>-0.183176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>110</td>\n",
       "      <td>-0.234010</td>\n",
       "      <td>-0.005789</td>\n",
       "      <td>-0.754281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179313</td>\n",
       "      <td>0.245597</td>\n",
       "      <td>-0.074740</td>\n",
       "      <td>0.326302</td>\n",
       "      <td>0.246354</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>-0.045136</td>\n",
       "      <td>-0.300550</td>\n",
       "      <td>0.424266</td>\n",
       "      <td>-0.487235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.360958</td>\n",
       "      <td>-0.032422</td>\n",
       "      <td>-1.517050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446681</td>\n",
       "      <td>0.821034</td>\n",
       "      <td>-0.187948</td>\n",
       "      <td>0.338291</td>\n",
       "      <td>0.571384</td>\n",
       "      <td>-0.449642</td>\n",
       "      <td>-0.185700</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>0.535742</td>\n",
       "      <td>-0.069742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.108012</td>\n",
       "      <td>-0.021497</td>\n",
       "      <td>-1.344048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748294</td>\n",
       "      <td>-0.040061</td>\n",
       "      <td>-0.212751</td>\n",
       "      <td>0.148267</td>\n",
       "      <td>-0.139923</td>\n",
       "      <td>-0.006358</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>-0.220026</td>\n",
       "      <td>1.054043</td>\n",
       "      <td>-0.075081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  word_count  num_stop_words  num_chars  num_punctuation_chars  \\\n",
       "0   ham          20               4        111                      9   \n",
       "1   ham           6               0         29                      6   \n",
       "2  spam          28               5        155                      5   \n",
       "3   ham          11               2         49                      6   \n",
       "4   ham          13               6         61                      2   \n",
       "\n",
       "   word_count_after_preprocessing  num_chars_after_preprocessing  \\\n",
       "0                              16                             82   \n",
       "1                               6                             23   \n",
       "2                              20                            110   \n",
       "3                               9                             35   \n",
       "4                               8                             40   \n",
       "\n",
       "   vector_dim_1  vector_dim_2  vector_dim_3  ...  vector_dim_91  \\\n",
       "0     -0.445367     -0.101509     -1.050856  ...       0.363760   \n",
       "1     -0.336330     -0.172123     -0.879673  ...       0.178105   \n",
       "2     -0.234010     -0.005789     -0.754281  ...       0.179313   \n",
       "3     -0.360958     -0.032422     -1.517050  ...       0.446681   \n",
       "4     -0.108012     -0.021497     -1.344048  ...       0.748294   \n",
       "\n",
       "   vector_dim_92  vector_dim_93  vector_dim_94  vector_dim_95  vector_dim_96  \\\n",
       "0       0.423471      -0.183125       0.123134       0.421487      -0.085384   \n",
       "1       0.469185      -0.159354       0.181287       0.370253      -0.151212   \n",
       "2       0.245597      -0.074740       0.326302       0.246354       0.009656   \n",
       "3       0.821034      -0.187948       0.338291       0.571384      -0.449642   \n",
       "4      -0.040061      -0.212751       0.148267      -0.139923      -0.006358   \n",
       "\n",
       "   vector_dim_97  vector_dim_98  vector_dim_99  vector_dim_100  \n",
       "0       0.096360      -0.311313       0.590059       -0.068110  \n",
       "1      -0.029242       0.017299       0.309134       -0.183176  \n",
       "2      -0.045136      -0.300550       0.424266       -0.487235  \n",
       "3      -0.185700       0.029383       0.535742       -0.069742  \n",
       "4       0.034125      -0.220026       1.054043       -0.075081  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>num_stop_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_punctuation_chars</th>\n",
       "      <th>word_count_after_preprocessing</th>\n",
       "      <th>num_chars_after_preprocessing</th>\n",
       "      <th>vector_dim_1</th>\n",
       "      <th>vector_dim_2</th>\n",
       "      <th>vector_dim_3</th>\n",
       "      <th>vector_dim_4</th>\n",
       "      <th>...</th>\n",
       "      <th>vector_dim_91</th>\n",
       "      <th>vector_dim_92</th>\n",
       "      <th>vector_dim_93</th>\n",
       "      <th>vector_dim_94</th>\n",
       "      <th>vector_dim_95</th>\n",
       "      <th>vector_dim_96</th>\n",
       "      <th>vector_dim_97</th>\n",
       "      <th>vector_dim_98</th>\n",
       "      <th>vector_dim_99</th>\n",
       "      <th>vector_dim_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>82</td>\n",
       "      <td>-0.445367</td>\n",
       "      <td>-0.101509</td>\n",
       "      <td>-1.050856</td>\n",
       "      <td>-0.263047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363760</td>\n",
       "      <td>0.423471</td>\n",
       "      <td>-0.183125</td>\n",
       "      <td>0.123134</td>\n",
       "      <td>0.421487</td>\n",
       "      <td>-0.085384</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>-0.311313</td>\n",
       "      <td>0.590059</td>\n",
       "      <td>-0.068110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.336330</td>\n",
       "      <td>-0.172123</td>\n",
       "      <td>-0.879673</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178105</td>\n",
       "      <td>0.469185</td>\n",
       "      <td>-0.159354</td>\n",
       "      <td>0.181287</td>\n",
       "      <td>0.370253</td>\n",
       "      <td>-0.151212</td>\n",
       "      <td>-0.029242</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>0.309134</td>\n",
       "      <td>-0.183176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>110</td>\n",
       "      <td>-0.234010</td>\n",
       "      <td>-0.005789</td>\n",
       "      <td>-0.754281</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179313</td>\n",
       "      <td>0.245597</td>\n",
       "      <td>-0.074740</td>\n",
       "      <td>0.326302</td>\n",
       "      <td>0.246354</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>-0.045136</td>\n",
       "      <td>-0.300550</td>\n",
       "      <td>0.424266</td>\n",
       "      <td>-0.487235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.360958</td>\n",
       "      <td>-0.032422</td>\n",
       "      <td>-1.517050</td>\n",
       "      <td>-0.111853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446681</td>\n",
       "      <td>0.821034</td>\n",
       "      <td>-0.187948</td>\n",
       "      <td>0.338291</td>\n",
       "      <td>0.571384</td>\n",
       "      <td>-0.449642</td>\n",
       "      <td>-0.185700</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>0.535742</td>\n",
       "      <td>-0.069742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.108012</td>\n",
       "      <td>-0.021497</td>\n",
       "      <td>-1.344048</td>\n",
       "      <td>-0.605199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748294</td>\n",
       "      <td>-0.040061</td>\n",
       "      <td>-0.212751</td>\n",
       "      <td>0.148267</td>\n",
       "      <td>-0.139923</td>\n",
       "      <td>-0.006358</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>-0.220026</td>\n",
       "      <td>1.054043</td>\n",
       "      <td>-0.075081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14612</th>\n",
       "      <td>131</td>\n",
       "      <td>59</td>\n",
       "      <td>745</td>\n",
       "      <td>24</td>\n",
       "      <td>74</td>\n",
       "      <td>517</td>\n",
       "      <td>-0.251930</td>\n",
       "      <td>-0.063167</td>\n",
       "      <td>-1.194805</td>\n",
       "      <td>-0.387192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651287</td>\n",
       "      <td>-0.020689</td>\n",
       "      <td>0.026659</td>\n",
       "      <td>0.290871</td>\n",
       "      <td>0.011417</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>-0.094306</td>\n",
       "      <td>-0.413245</td>\n",
       "      <td>0.968019</td>\n",
       "      <td>-0.213552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14613</th>\n",
       "      <td>121</td>\n",
       "      <td>62</td>\n",
       "      <td>670</td>\n",
       "      <td>18</td>\n",
       "      <td>63</td>\n",
       "      <td>430</td>\n",
       "      <td>-0.188276</td>\n",
       "      <td>-0.060201</td>\n",
       "      <td>-1.234956</td>\n",
       "      <td>-0.394533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824768</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>0.166092</td>\n",
       "      <td>0.286987</td>\n",
       "      <td>-0.115114</td>\n",
       "      <td>-0.072424</td>\n",
       "      <td>-0.317539</td>\n",
       "      <td>-0.333784</td>\n",
       "      <td>0.966461</td>\n",
       "      <td>-0.284511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14614</th>\n",
       "      <td>141</td>\n",
       "      <td>72</td>\n",
       "      <td>770</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "      <td>490</td>\n",
       "      <td>-0.237662</td>\n",
       "      <td>-0.076631</td>\n",
       "      <td>-1.247667</td>\n",
       "      <td>-0.374296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801583</td>\n",
       "      <td>-0.036325</td>\n",
       "      <td>0.300470</td>\n",
       "      <td>0.293482</td>\n",
       "      <td>-0.156067</td>\n",
       "      <td>-0.117382</td>\n",
       "      <td>-0.343503</td>\n",
       "      <td>-0.324489</td>\n",
       "      <td>0.929325</td>\n",
       "      <td>-0.190733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14615</th>\n",
       "      <td>86</td>\n",
       "      <td>47</td>\n",
       "      <td>448</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>266</td>\n",
       "      <td>-0.340769</td>\n",
       "      <td>-0.058809</td>\n",
       "      <td>-1.138488</td>\n",
       "      <td>-0.384569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681083</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.198969</td>\n",
       "      <td>0.235866</td>\n",
       "      <td>-0.116819</td>\n",
       "      <td>-0.105489</td>\n",
       "      <td>-0.097344</td>\n",
       "      <td>-0.315073</td>\n",
       "      <td>0.851146</td>\n",
       "      <td>-0.265891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14616</th>\n",
       "      <td>260</td>\n",
       "      <td>139</td>\n",
       "      <td>1363</td>\n",
       "      <td>35</td>\n",
       "      <td>126</td>\n",
       "      <td>845</td>\n",
       "      <td>-0.298359</td>\n",
       "      <td>-0.085764</td>\n",
       "      <td>-1.240260</td>\n",
       "      <td>-0.396023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803427</td>\n",
       "      <td>0.030206</td>\n",
       "      <td>0.115804</td>\n",
       "      <td>0.236635</td>\n",
       "      <td>-0.126242</td>\n",
       "      <td>-0.068015</td>\n",
       "      <td>-0.212386</td>\n",
       "      <td>-0.343189</td>\n",
       "      <td>0.971015</td>\n",
       "      <td>-0.242007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14617 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_count  num_stop_words  num_chars  num_punctuation_chars  \\\n",
       "0              20               4        111                      9   \n",
       "1               6               0         29                      6   \n",
       "2              28               5        155                      5   \n",
       "3              11               2         49                      6   \n",
       "4              13               6         61                      2   \n",
       "...           ...             ...        ...                    ...   \n",
       "14612         131              59        745                     24   \n",
       "14613         121              62        670                     18   \n",
       "14614         141              72        770                      9   \n",
       "14615          86              47        448                     16   \n",
       "14616         260             139       1363                     35   \n",
       "\n",
       "       word_count_after_preprocessing  num_chars_after_preprocessing  \\\n",
       "0                                  16                             82   \n",
       "1                                   6                             23   \n",
       "2                                  20                            110   \n",
       "3                                   9                             35   \n",
       "4                                   8                             40   \n",
       "...                               ...                            ...   \n",
       "14612                              74                            517   \n",
       "14613                              63                            430   \n",
       "14614                              69                            490   \n",
       "14615                              41                            266   \n",
       "14616                             126                            845   \n",
       "\n",
       "       vector_dim_1  vector_dim_2  vector_dim_3  vector_dim_4  ...  \\\n",
       "0         -0.445367     -0.101509     -1.050856     -0.263047  ...   \n",
       "1         -0.336330     -0.172123     -0.879673     -0.000336  ...   \n",
       "2         -0.234010     -0.005789     -0.754281      0.017621  ...   \n",
       "3         -0.360958     -0.032422     -1.517050     -0.111853  ...   \n",
       "4         -0.108012     -0.021497     -1.344048     -0.605199  ...   \n",
       "...             ...           ...           ...           ...  ...   \n",
       "14612     -0.251930     -0.063167     -1.194805     -0.387192  ...   \n",
       "14613     -0.188276     -0.060201     -1.234956     -0.394533  ...   \n",
       "14614     -0.237662     -0.076631     -1.247667     -0.374296  ...   \n",
       "14615     -0.340769     -0.058809     -1.138488     -0.384569  ...   \n",
       "14616     -0.298359     -0.085764     -1.240260     -0.396023  ...   \n",
       "\n",
       "       vector_dim_91  vector_dim_92  vector_dim_93  vector_dim_94  \\\n",
       "0           0.363760       0.423471      -0.183125       0.123134   \n",
       "1           0.178105       0.469185      -0.159354       0.181287   \n",
       "2           0.179313       0.245597      -0.074740       0.326302   \n",
       "3           0.446681       0.821034      -0.187948       0.338291   \n",
       "4           0.748294      -0.040061      -0.212751       0.148267   \n",
       "...              ...            ...            ...            ...   \n",
       "14612       0.651287      -0.020689       0.026659       0.290871   \n",
       "14613       0.824768      -0.053670       0.166092       0.286987   \n",
       "14614       0.801583      -0.036325       0.300470       0.293482   \n",
       "14615       0.681083       0.017155       0.198969       0.235866   \n",
       "14616       0.803427       0.030206       0.115804       0.236635   \n",
       "\n",
       "       vector_dim_95  vector_dim_96  vector_dim_97  vector_dim_98  \\\n",
       "0           0.421487      -0.085384       0.096360      -0.311313   \n",
       "1           0.370253      -0.151212      -0.029242       0.017299   \n",
       "2           0.246354       0.009656      -0.045136      -0.300550   \n",
       "3           0.571384      -0.449642      -0.185700       0.029383   \n",
       "4          -0.139923      -0.006358       0.034125      -0.220026   \n",
       "...              ...            ...            ...            ...   \n",
       "14612       0.011417       0.002676      -0.094306      -0.413245   \n",
       "14613      -0.115114      -0.072424      -0.317539      -0.333784   \n",
       "14614      -0.156067      -0.117382      -0.343503      -0.324489   \n",
       "14615      -0.116819      -0.105489      -0.097344      -0.315073   \n",
       "14616      -0.126242      -0.068015      -0.212386      -0.343189   \n",
       "\n",
       "       vector_dim_99  vector_dim_100  \n",
       "0           0.590059       -0.068110  \n",
       "1           0.309134       -0.183176  \n",
       "2           0.424266       -0.487235  \n",
       "3           0.535742       -0.069742  \n",
       "4           1.054043       -0.075081  \n",
       "...              ...             ...  \n",
       "14612       0.968019       -0.213552  \n",
       "14613       0.966461       -0.284511  \n",
       "14614       0.929325       -0.190733  \n",
       "14615       0.851146       -0.265891  \n",
       "14616       0.971015       -0.242007  \n",
       "\n",
       "[14617 rows x 106 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "14612    0\n",
       "14613    0\n",
       "14614    0\n",
       "14615    0\n",
       "14616    0\n",
       "Name: label, Length: 14617, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the Random Forest model with class_weight='balanced'\n",
    "rf_model = RandomForestClassifier(n_estimators=100,class_weight='balanced', random_state=42)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[2219   36]\n",
      " [ 105  564]]\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix and classification report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      2255\n",
      "           1       0.94      0.84      0.89       669\n",
      "\n",
      "    accuracy                           0.95      2924\n",
      "   macro avg       0.95      0.91      0.93      2924\n",
      "weighted avg       0.95      0.95      0.95      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014995741070333664"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_proba = rf_model.predict_proba(X_test)\n",
    "roc_auc_score(y_test, y_pred_proba[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850042589296664"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_proba = rf_model.predict_proba(X_test)\n",
    "roc_auc_score(y_test, y_pred_proba[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found, starting manual grid search from scratch...\n",
      "Model 1/32 evaluated with penalty: 146.5.\n",
      "Model 2/32 evaluated with penalty: 176.0.\n",
      "Model 3/32 evaluated with penalty: 148.0.\n",
      "Model 4/32 evaluated with penalty: 177.5.\n",
      "Model 5/32 evaluated with penalty: 144.0.\n",
      "Model 6/32 evaluated with penalty: 177.0.\n",
      "Model 7/32 evaluated with penalty: 155.0.\n",
      "Model 8/32 evaluated with penalty: 177.0.\n",
      "Model 9/32 evaluated with penalty: 91.0.\n",
      "Model 10/32 evaluated with penalty: 115.5.\n",
      "Model 11/32 evaluated with penalty: 97.5.\n",
      "Model 12/32 evaluated with penalty: 108.5.\n",
      "Model 13/32 evaluated with penalty: 94.5.\n",
      "Model 14/32 evaluated with penalty: 114.5.\n",
      "Model 15/32 evaluated with penalty: 90.5.\n",
      "Model 16/32 evaluated with penalty: 115.5.\n",
      "Model 17/32 evaluated with penalty: 144.0.\n",
      "Model 18/32 evaluated with penalty: 170.5.\n",
      "Model 19/32 evaluated with penalty: 152.0.\n",
      "Model 20/32 evaluated with penalty: 173.0.\n",
      "Model 21/32 evaluated with penalty: 145.5.\n",
      "Model 22/32 evaluated with penalty: 170.5.\n",
      "Model 23/32 evaluated with penalty: 149.5.\n",
      "Model 24/32 evaluated with penalty: 172.5.\n",
      "Model 25/32 evaluated with penalty: 91.0.\n",
      "Model 26/32 evaluated with penalty: 114.0.\n",
      "Model 27/32 evaluated with penalty: 101.0.\n",
      "Model 28/32 evaluated with penalty: 109.0.\n",
      "Model 29/32 evaluated with penalty: 92.0.\n",
      "Model 30/32 evaluated with penalty: 110.5.\n",
      "Model 31/32 evaluated with penalty: 96.5.\n",
      "Model 32/32 evaluated with penalty: 111.0.\n",
      "    n_estimators  max_depth  min_samples_split  min_samples_leaf max_features  \\\n",
      "0            100         10                  2                 1         sqrt   \n",
      "1            100         10                  2                 1          NaN   \n",
      "2            100         10                  2                 2         sqrt   \n",
      "3            100         10                  2                 2          NaN   \n",
      "4            100         10                  5                 1         sqrt   \n",
      "5            100         10                  5                 1          NaN   \n",
      "6            100         10                  5                 2         sqrt   \n",
      "7            100         10                  5                 2          NaN   \n",
      "8            100         20                  2                 1         sqrt   \n",
      "9            100         20                  2                 1          NaN   \n",
      "10           100         20                  2                 2         sqrt   \n",
      "11           100         20                  2                 2          NaN   \n",
      "12           100         20                  5                 1         sqrt   \n",
      "13           100         20                  5                 1          NaN   \n",
      "14           100         20                  5                 2         sqrt   \n",
      "15           100         20                  5                 2          NaN   \n",
      "16           200         10                  2                 1         sqrt   \n",
      "17           200         10                  2                 1          NaN   \n",
      "18           200         10                  2                 2         sqrt   \n",
      "19           200         10                  2                 2          NaN   \n",
      "20           200         10                  5                 1         sqrt   \n",
      "21           200         10                  5                 1          NaN   \n",
      "22           200         10                  5                 2         sqrt   \n",
      "23           200         10                  5                 2          NaN   \n",
      "24           200         20                  2                 1         sqrt   \n",
      "25           200         20                  2                 1          NaN   \n",
      "26           200         20                  2                 2         sqrt   \n",
      "27           200         20                  2                 2          NaN   \n",
      "28           200         20                  5                 1         sqrt   \n",
      "29           200         20                  5                 1          NaN   \n",
      "30           200         20                  5                 2         sqrt   \n",
      "31           200         20                  5                 2          NaN   \n",
      "\n",
      "     FP   FN  Penalty  \n",
      "0   112   69    146.5  \n",
      "1   139   74    176.0  \n",
      "2   113   70    148.0  \n",
      "3   140   75    177.5  \n",
      "4   110   68    144.0  \n",
      "5   139   76    177.0  \n",
      "6   119   72    155.0  \n",
      "7   140   74    177.0  \n",
      "8    41  100     91.0  \n",
      "9    63  105    115.5  \n",
      "10   50   95     97.5  \n",
      "11   60   97    108.5  \n",
      "12   44  101     94.5  \n",
      "13   64  101    114.5  \n",
      "14   43   95     90.5  \n",
      "15   67   97    115.5  \n",
      "16  109   70    144.0  \n",
      "17  133   75    170.5  \n",
      "18  118   68    152.0  \n",
      "19  136   74    173.0  \n",
      "20  111   69    145.5  \n",
      "21  133   75    170.5  \n",
      "22  113   73    149.5  \n",
      "23  136   73    172.5  \n",
      "24   40  102     91.0  \n",
      "25   61  106    114.0  \n",
      "26   52   98    101.0  \n",
      "27   59  100    109.0  \n",
      "28   43   98     92.0  \n",
      "29   60  101    110.5  \n",
      "30   49   95     96.5  \n",
      "31   62   98    111.0  \n",
      "Best hyperparameters: n_estimators=100, max_depth=20, min_samples_split=5, min_samples_leaf=2, max_features=sqrt with penalty 90.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Custom scoring function\n",
    "def custom_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    penalty = fp + 0.5 * fn  # Adjust weights if necessary\n",
    "    return penalty  # We return penalty as lower is better\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', None]\n",
    "}\n",
    "\n",
    "# Define the checkpoint file path\n",
    "checkpoint_path = 'manual_search_checkpoint.pkl'\n",
    "\n",
    "# Load checkpoint or initialize\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"Loading checkpoint from previous run...\")\n",
    "    checkpoint_data = joblib.load(checkpoint_path)\n",
    "    start_index = checkpoint_data['start_index']\n",
    "    results = checkpoint_data['results']\n",
    "else:\n",
    "    print(\"No checkpoint found, starting manual grid search from scratch...\")\n",
    "    start_index = 0\n",
    "    results = []\n",
    "\n",
    "# Create the parameter combinations manually\n",
    "from itertools import product\n",
    "param_combinations = list(product(param_grid['n_estimators'],\n",
    "                                  param_grid['max_depth'],\n",
    "                                  param_grid['min_samples_split'],\n",
    "                                  param_grid['min_samples_leaf'],\n",
    "                                  param_grid['max_features']))\n",
    "\n",
    "# Real-time update CSV file\n",
    "csv_file_path = 'manual_search_results.csv'\n",
    "if not os.path.exists(csv_file_path):\n",
    "    # If file doesn't exist, create it with the header\n",
    "    pd.DataFrame(columns=['n_estimators', 'max_depth', 'min_samples_split', \n",
    "                          'min_samples_leaf', 'max_features', 'FP', 'FN', 'Penalty']).to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Variable to track the best model\n",
    "best_penalty = float('inf')\n",
    "best_params = None\n",
    "\n",
    "# Train 32 models based on parameter combinations\n",
    "try:\n",
    "    for i in range(start_index, min(len(param_combinations), 32)):\n",
    "        params = param_combinations[i]\n",
    "\n",
    "        # Unpack the parameters\n",
    "        n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features = params\n",
    "\n",
    "        # Initialize RandomForestClassifier with the current parameters\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            max_features=max_features,\n",
    "            class_weight='balanced',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred = rf.predict(X_test)\n",
    "\n",
    "        # Compute confusion matrix and extract FP, FN\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        # Calculate the penalty for the current model\n",
    "        penalty = custom_score(y_test, y_pred)\n",
    "\n",
    "        # Append the results to the DataFrame\n",
    "        new_row = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split,\n",
    "            'min_samples_leaf': min_samples_leaf,\n",
    "            'max_features': max_features,\n",
    "            'FP': fp,\n",
    "            'FN': fn,\n",
    "            'Penalty': penalty\n",
    "        }\n",
    "\n",
    "        # Append results to the CSV file immediately after each evaluation\n",
    "        pd.DataFrame([new_row]).to_csv(csv_file_path, index=False, mode='a', header=False)\n",
    "\n",
    "        # Check if this is the best model so far\n",
    "        if penalty < best_penalty:\n",
    "            best_penalty = penalty\n",
    "            best_params = params\n",
    "\n",
    "        # Save progress to checkpoint after each model\n",
    "        results.append(new_row)\n",
    "        checkpoint_data = {'start_index': i + 1, 'results': results}\n",
    "        joblib.dump(checkpoint_data, checkpoint_path)\n",
    "\n",
    "        print(f\"Model {i+1}/32 evaluated with penalty: {penalty}.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # Save the current progress to a checkpoint file before exiting\n",
    "    checkpoint_data = {'start_index': i, 'results': results}\n",
    "    joblib.dump(checkpoint_data, checkpoint_path)\n",
    "    print(\"Progress saved to checkpoint.\")\n",
    "\n",
    "# After the process completes, delete the checkpoint file if desired\n",
    "if len(results) == 32:\n",
    "    os.remove(checkpoint_path)  # Remove checkpoint file after successful completion\n",
    "\n",
    "# Show the results DataFrame\n",
    "print(pd.read_csv(csv_file_path))\n",
    "\n",
    "# Print the best hyperparameters\n",
    "if best_params:\n",
    "    print(f\"Best hyperparameters: n_estimators={best_params[0]}, max_depth={best_params[1]}, \"\n",
    "          f\"min_samples_split={best_params[2]}, min_samples_leaf={best_params[3]}, \"\n",
    "          f\"max_features={best_params[4]} with penalty {best_penalty}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[2193   62]\n",
      " [  98  571]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      2255\n",
      "           1       0.90      0.85      0.88       669\n",
      "\n",
      "    accuracy                           0.95      2924\n",
      "   macro avg       0.93      0.91      0.92      2924\n",
      "weighted avg       0.94      0.95      0.94      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIth best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=20,\n",
       "                       min_samples_leaf=2, min_samples_split=5,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=20,\n",
       "                       min_samples_leaf=2, min_samples_split=5,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
       "                       min_samples_leaf=2, min_samples_split=5,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the Random Forest model with class_weight='balanced'\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=20, min_samples_split=5, min_samples_leaf=2, max_features='sqrt',class_weight='balanced', random_state=42)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[2219   36]\n",
      " [ 105  564]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      2255\n",
      "           1       0.94      0.84      0.89       669\n",
      "\n",
      "    accuracy                           0.95      2924\n",
      "   macro avg       0.95      0.91      0.93      2924\n",
      "weighted avg       0.95      0.95      0.95      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open('random_forest__best_model.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
